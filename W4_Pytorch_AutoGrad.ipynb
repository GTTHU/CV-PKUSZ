{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3125],\n",
      "        [-0.8072],\n",
      "        [-1.1902],\n",
      "        [-0.8574]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自动求导机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3547],\n",
      "        [-0.1142],\n",
      "        [-2.5544],\n",
      "        [ 0.0165]], requires_grad=True)\n",
      "tensor([[-0.0953],\n",
      "        [ 0.4071],\n",
      "        [-0.6318],\n",
      "        [ 1.0965]], requires_grad=True)\n",
      "tensor([[ 1.7454, -0.5501,  1.0740, -0.3665],\n",
      "        [ 0.2229, -0.6237, -0.8042, -1.5603],\n",
      "        [ 1.1954,  0.5553, -0.1137, -2.4699],\n",
      "        [-0.6802, -0.2414,  1.3333, -1.3997]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,1, requires_grad=True)\n",
    "y = torch.randn(4,1, requires_grad=True)\n",
    "W = torch.randn(4,4)\n",
    "print(x)\n",
    "print(y)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.0989, grad_fn=<TraceBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.trace(W.mm(y).t().mm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5218,  0.5242,  0.8955,  0.8551],\n",
       "        [ 0.1679,  0.1687,  0.2882,  0.2753],\n",
       "        [ 3.7571,  3.7750,  6.4482,  6.1578],\n",
       "        [-0.0242, -0.0244, -0.0416, -0.0397]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mm(W.mm(y).t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.0989, grad_fn=<TraceBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.trace(x.mm(W.mm(y).t()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $z = x^T W y $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.0989]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "z = torch.mm(torch.mm(torch.t(x), W),y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.0989]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "z = x.t().mm(W).mm(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4708],\n",
      "        [-1.4778],\n",
      "        [-2.5243],\n",
      "        [-2.4106]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4708],\n",
      "        [-1.4778],\n",
      "        [-2.5243],\n",
      "        [-2.4106]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(W.mm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.7095],\n",
      "        [-1.1562],\n",
      "        [ 0.0233],\n",
      "        [ 6.5944]])\n"
     ]
    }
   ],
   "source": [
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.7095],\n",
      "        [-1.1562],\n",
      "        [ 0.0233],\n",
      "        [ 6.5944]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(W.t().mm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 默认情况下，定义的tensor属性requires_grad为false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9573],\n",
      "        [ 0.5544],\n",
      "        [-0.8530],\n",
      "        [ 1.2618]], requires_grad=True)\n",
      "tensor([[3.5437]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,1, requires_grad=True)\n",
    "print(x)\n",
    "y = torch.mm(torch.t(x),x)\n",
    "print(y)\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9146],\n",
      "        [ 1.1089],\n",
      "        [-1.7061],\n",
      "        [ 2.5237]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.5437]], grad_fn=<MmBackward>)\n",
      "tensor([[-1.9146],\n",
      "        [ 1.1089],\n",
      "        [-1.7061],\n",
      "        [ 2.5237]])\n",
      "tensor([[-1.9146],\n",
      "        [ 1.1089],\n",
      "        [-1.7061],\n",
      "        [ 2.5237]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(x.grad)\n",
    "print(2*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 给定数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "        [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "        [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "        [ 0.1198,  1.2377,  1.1168, -0.2473],\n",
      "        [-1.3527, -1.6959,  0.5667,  0.7935],\n",
      "        [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
      "        [-0.2159, -0.7425,  0.5627,  0.2596],\n",
      "        [-0.1740, -0.6787,  0.9383,  0.4889],\n",
      "        [ 1.2032,  0.0845, -1.2001, -0.0048],\n",
      "        [-0.5181, -0.3067, -1.5810,  1.7066]], requires_grad=True)\n",
      "tensor([[ 1.5091,  2.0820,  1.7067,  2.3804],\n",
      "        [-1.1256, -0.3170, -1.0925, -0.0852],\n",
      "        [ 0.3276, -0.7607, -1.5991,  0.0185],\n",
      "        [-0.7504,  0.1854,  0.6211,  0.6382],\n",
      "        [-0.0033, -0.5344,  1.1687,  0.3945],\n",
      "        [ 1.9415,  0.7915, -0.0203, -0.4372],\n",
      "        [-0.2188, -2.4351, -0.0729, -0.0340],\n",
      "        [ 0.9625,  0.3492, -0.9215, -0.0562],\n",
      "        [-0.6227, -0.4637,  1.9218, -0.4025],\n",
      "        [ 0.1239,  1.1648,  0.9234,  1.3873]], requires_grad=True)\n",
      "tensor([[ 0.2055, -0.4503, -0.5731, -0.5554],\n",
      "        [ 0.5943,  1.5419,  0.5073, -0.5910],\n",
      "        [-1.3253,  0.1886, -0.0691, -0.4949],\n",
      "        [-1.4959, -0.1938,  0.4455,  1.3253]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "x = torch.randn(10, 4, requires_grad=True)\n",
    "W = torch.randn(4, 4, requires_grad=True)\n",
    "y = torch.randn(10, 4, requires_grad=True)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目标函数 $f = ||max(XW,0)-Y||^2_F $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $f = ||\\hat{Y}-Y||^2_F $; $\\hat{Y} = max(Z,0)$; $Z = XW$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = (torch.clamp(x.mm(W), 0) - y).pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0649, -1.2330, -0.1154,  0.8553],\n",
      "        [ 4.1687,  1.0353, -1.0558, -3.5272],\n",
      "        [-1.6094, -2.0869, -0.7125,  0.8028],\n",
      "        [-0.3500,  2.1129,  0.3719, -1.6785],\n",
      "        [-3.2240, -2.0529,  0.2291,  2.5247],\n",
      "        [-3.1207, -3.0911, -0.2830,  3.2112],\n",
      "        [-1.6198, -0.9920, -0.1762,  0.6243],\n",
      "        [-2.4140, -0.8861, -0.0917,  0.6813],\n",
      "        [ 1.8953, -0.6369, -0.5659, -0.1305],\n",
      "        [-0.7464, -0.8685,  1.0108,  3.5132]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "z = x.mm(W)\n",
    "z.retain_grad()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0649, 0.0000, 0.0000, 0.8553],\n",
      "        [4.1687, 1.0353, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.8028],\n",
      "        [0.0000, 2.1129, 0.3719, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2291, 2.5247],\n",
      "        [0.0000, 0.0000, 0.0000, 3.2112],\n",
      "        [0.0000, 0.0000, 0.0000, 0.6243],\n",
      "        [0.0000, 0.0000, 0.0000, 0.6813],\n",
      "        [1.8953, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0108, 3.5132]], grad_fn=<ClampBackward>)\n"
     ]
    }
   ],
   "source": [
    "y_hat = torch.clamp(z, 0)\n",
    "y_hat.retain_grad()\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(99.9048, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "f = (y_hat - y).pow(2).sum()\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W.grad.zero_()\n",
    "# print(W.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8885, -0.0000, -0.0000, -3.0501],\n",
      "        [10.5886,  2.7045,  0.0000,  0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  1.5687],\n",
      "        [ 0.0000,  3.8551, -0.4984, -0.0000],\n",
      "        [ 0.0000,  0.0000, -1.8791,  4.2604],\n",
      "        [-0.0000, -0.0000,  0.0000,  7.2968],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.3166],\n",
      "        [-0.0000, -0.0000,  0.0000,  1.4750],\n",
      "        [ 5.0359,  0.0000, -0.0000,  0.0000],\n",
      "        [-0.0000, -0.0000,  0.1749,  4.2519]])\n",
      "tensor([[-2.8885e+00, -4.1639e+00, -3.4134e+00, -3.0501e+00],\n",
      "        [ 1.0589e+01,  2.7045e+00,  2.1849e+00,  1.7039e-01],\n",
      "        [-6.5523e-01,  1.5214e+00,  3.1982e+00,  1.5687e+00],\n",
      "        [ 1.5009e+00,  3.8551e+00, -4.9843e-01, -1.2764e+00],\n",
      "        [ 6.6077e-03,  1.0689e+00, -1.8791e+00,  4.2604e+00],\n",
      "        [-3.8829e+00, -1.5830e+00,  4.0504e-02,  7.2968e+00],\n",
      "        [ 4.3767e-01,  4.8701e+00,  1.4583e-01,  1.3166e+00],\n",
      "        [-1.9250e+00, -6.9834e-01,  1.8429e+00,  1.4750e+00],\n",
      "        [ 5.0359e+00,  9.2744e-01, -3.8436e+00,  8.0509e-01],\n",
      "        [-2.4780e-01, -2.3296e+00,  1.7491e-01,  4.2519e+00]])\n",
      "tensor([[ 18.2980,   2.7573,   2.3914,  -0.1974],\n",
      "        [ 11.0817,   6.6428,   2.5163, -20.3225],\n",
      "        [ -8.6662,   3.4506,  -1.8979,  -3.3608],\n",
      "        [-21.1681,  -6.6739,  -1.0693,  27.0278]])\n",
      "tensor([[  1.1002,   0.0860,   5.3377,   0.2788],\n",
      "        [  0.9583,  10.4633, -13.5234, -16.3639],\n",
      "        [ -0.8712,  -0.9272,  -0.7764,   2.0790],\n",
      "        [ -1.4504,   5.6914,   0.7613,  -0.9693],\n",
      "        [ -1.2892,  -3.4714,  -1.9788,   4.8091],\n",
      "        [ -4.0523,  -4.3127,  -3.6114,   9.6703],\n",
      "        [ -0.7312,  -0.7782,  -0.6516,   1.7449],\n",
      "        [ -0.8191,  -0.8718,  -0.7300,   1.9547],\n",
      "        [  1.0350,   2.9930,  -6.6743,  -7.5333],\n",
      "        [ -2.4616,  -2.4243,  -2.1164,   5.7128]])\n",
      "tensor([[ 2.8885e+00,  4.1639e+00,  3.4134e+00,  3.0501e+00],\n",
      "        [-1.0589e+01, -2.7045e+00, -2.1849e+00, -1.7039e-01],\n",
      "        [ 6.5523e-01, -1.5214e+00, -3.1982e+00, -1.5687e+00],\n",
      "        [-1.5009e+00, -3.8551e+00,  4.9843e-01,  1.2764e+00],\n",
      "        [-6.6077e-03, -1.0689e+00,  1.8791e+00, -4.2604e+00],\n",
      "        [ 3.8829e+00,  1.5830e+00, -4.0504e-02, -7.2968e+00],\n",
      "        [-4.3767e-01, -4.8701e+00, -1.4583e-01, -1.3166e+00],\n",
      "        [ 1.9250e+00,  6.9834e-01, -1.8429e+00, -1.4750e+00],\n",
      "        [-5.0359e+00, -9.2744e-01,  3.8436e+00, -8.0509e-01],\n",
      "        [ 2.4780e-01,  2.3296e+00, -1.7491e-01, -4.2519e+00]])\n"
     ]
    }
   ],
   "source": [
    "print(z.grad)\n",
    "print(y_hat.grad)\n",
    "print(W.grad)\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 公式推导求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8885e+00, -4.1639e+00, -3.4134e+00, -3.0501e+00],\n",
      "        [ 1.0589e+01,  2.7045e+00,  2.1849e+00,  1.7039e-01],\n",
      "        [-6.5523e-01,  1.5214e+00,  3.1982e+00,  1.5687e+00],\n",
      "        [ 1.5009e+00,  3.8551e+00, -4.9843e-01, -1.2764e+00],\n",
      "        [ 6.6077e-03,  1.0689e+00, -1.8791e+00,  4.2604e+00],\n",
      "        [-3.8829e+00, -1.5830e+00,  4.0504e-02,  7.2968e+00],\n",
      "        [ 4.3767e-01,  4.8701e+00,  1.4583e-01,  1.3166e+00],\n",
      "        [-1.9250e+00, -6.9834e-01,  1.8429e+00,  1.4750e+00],\n",
      "        [ 5.0359e+00,  9.2744e-01, -3.8436e+00,  8.0509e-01],\n",
      "        [-2.4780e-01, -2.3296e+00,  1.7491e-01,  4.2519e+00]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_hat_grad = 2 * (y_hat - y)\n",
    "print(y_hat_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8885,  0.0000,  0.0000, -3.0501],\n",
      "        [10.5886,  2.7045,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.5687],\n",
      "        [ 0.0000,  3.8551, -0.4984,  0.0000],\n",
      "        [ 0.0000,  0.0000, -1.8791,  4.2604],\n",
      "        [ 0.0000,  0.0000,  0.0000,  7.2968],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.3166],\n",
      "        [ 0.0000,  0.0000,  0.0000,  1.4750],\n",
      "        [ 5.0359,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.1749,  4.2519]], grad_fn=<IndexPutBackward>)\n"
     ]
    }
   ],
   "source": [
    "y_hat_grad[z <= 0] = 0\n",
    "z_grad = y_hat_grad\n",
    "print(z_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 18.2980,   2.7573,   2.3914,  -0.1974],\n",
      "        [ 11.0817,   6.6428,   2.5163, -20.3225],\n",
      "        [ -8.6662,   3.4506,  -1.8979,  -3.3608],\n",
      "        [-21.1681,  -6.6739,  -1.0693,  27.0278]], grad_fn=<MmBackward>)\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "W_grad = x.t().mm(z_grad)\n",
    "print(W_grad)\n",
    "print(W.grad==W_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.1002,   0.0860,   5.3377,   0.2788],\n",
      "        [  0.9583,  10.4633, -13.5234, -16.3639],\n",
      "        [ -0.8712,  -0.9272,  -0.7764,   2.0790],\n",
      "        [ -1.4504,   5.6914,   0.7613,  -0.9693],\n",
      "        [ -1.2892,  -3.4714,  -1.9788,   4.8091],\n",
      "        [ -4.0523,  -4.3127,  -3.6114,   9.6703],\n",
      "        [ -0.7312,  -0.7782,  -0.6516,   1.7449],\n",
      "        [ -0.8191,  -0.8718,  -0.7300,   1.9547],\n",
      "        [  1.0350,   2.9930,  -6.6743,  -7.5333],\n",
      "        [ -2.4616,  -2.4243,  -2.1164,   5.7128]], grad_fn=<MmBackward>)\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "x_grad = z_grad.mm(W.t())\n",
    "print(x_grad)\n",
    "print(x.grad==x_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.8885e+00,  4.1639e+00,  3.4134e+00,  3.0501e+00],\n",
      "        [-1.0589e+01, -2.7045e+00, -2.1849e+00, -1.7039e-01],\n",
      "        [ 6.5523e-01, -1.5214e+00, -3.1982e+00, -1.5687e+00],\n",
      "        [-1.5009e+00, -3.8551e+00,  4.9843e-01,  1.2764e+00],\n",
      "        [-6.6077e-03, -1.0689e+00,  1.8791e+00, -4.2604e+00],\n",
      "        [ 3.8829e+00,  1.5830e+00, -4.0504e-02, -7.2968e+00],\n",
      "        [-4.3767e-01, -4.8701e+00, -1.4583e-01, -1.3166e+00],\n",
      "        [ 1.9250e+00,  6.9834e-01, -1.8429e+00, -1.4750e+00],\n",
      "        [-5.0359e+00, -9.2744e-01,  3.8436e+00, -8.0509e-01],\n",
      "        [ 2.4780e-01,  2.3296e+00, -1.7491e-01, -4.2519e+00]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "y_grad = -2 * (y_hat - y)\n",
    "print(y_grad)\n",
    "print(y.grad==y_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Tensor 与 Numpy 转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.82343957  0.36097133  0.1333064   0.92750436]\n",
      " [-0.37621722 -0.16657024  2.01840463 -2.18181294]\n",
      " [ 0.99416876  0.34965001  0.54580467  0.66424866]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "a = np.random.randn(3,4)\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8234,  0.3610,  0.1333,  0.9275],\n",
      "        [-0.3762, -0.1666,  2.0184, -2.1818],\n",
      "        [ 0.9942,  0.3497,  0.5458,  0.6642]], dtype=torch.float64)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "a_tensor = torch.from_numpy(a)\n",
    "print(a_tensor)\n",
    "print(type(a_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.82343957  0.36097133  0.1333064   0.92750436]\n",
      " [-0.37621722 -0.16657024  2.01840463 -2.18181294]\n",
      " [ 0.99416876  0.34965001  0.54580467  0.66424866]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "b = a_tensor.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.4583958  -0.33598807 -1.5699861   1.2315004 ]\n",
      " [ 1.3946317   1.1711024   0.43351194 -1.7342502 ]\n",
      " [-1.3360486   0.88709605  0.76795745  0.057113  ]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "d_tensor = torch.randn(3, 4, requires_grad=False)\n",
    "d_numpy = d_tensor.numpy()\n",
    "print(d_numpy)\n",
    "print(type(d_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jh/t42vtdjj45n_rk6p8vghb2rm0000gp/T/ipykernel_40111/56438132.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0md_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0md_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "d_tensor = torch.randn(3, 4, requires_grad=True)\n",
    "d_numpy = d_tensor.numpy()\n",
    "print(d_numpy)\n",
    "print(type(d_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.6461524  -0.15909262 -1.7786636   0.84765124]\n",
      " [ 0.24594283 -0.13116787 -0.17851807 -0.5958931 ]\n",
      " [ 0.27386975  0.5679263  -0.67310244 -1.2095324 ]]\n",
      "tensor([[-0.6462, -0.1591, -1.7787,  0.8477],\n",
      "        [ 0.2459, -0.1312, -0.1785, -0.5959],\n",
      "        [ 0.2739,  0.5679, -0.6731, -1.2095]])\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "d_tensor = torch.randn(3, 4, requires_grad=True)\n",
    "d_numpy = d_tensor.data.numpy()\n",
    "print(d_numpy)\n",
    "print(d_tensor.data)\n",
    "print(type(d_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
